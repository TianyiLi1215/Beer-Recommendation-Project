{"cells":[{"cell_type":"markdown","source":["### Project Title : Beer Recommendation"],"metadata":{}},{"cell_type":"markdown","source":["### Introduction\n##### Many online businesses rely on customer reviews and ratings. It is especially important in the ecommerce industry where customer engagements are greatly impacted by ratings. Websites rely on rating data to power its recommendation engine to provide the best recommendations that are personalized and most relevant to the user and make profits. \n##### This project focuses on the beer industry/beer online shops. To recommend the users with their potential ideal product based on their past ratings or features of the beers will be the key motivation."],"metadata":{}},{"cell_type":"markdown","source":["#### Import libraries"],"metadata":{}},{"cell_type":"code","source":["import pyspark.sql.functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.sql.window import Window \nimport numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport math\nimport os\nos.environ[\"PYSPARK_PYTHON\"] = \"python3\"\nimport urllib\nfrom pyspark.sql import SparkSession\n## Recommendation Engine \nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.recommendation import ALS as ml_als\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"markdown","source":["#### Data ETL"],"metadata":{}},{"cell_type":"code","source":["## setup spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"beer review\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["## Create Dataframe and SQL Table\n## load data into dataframe and create sql tables\nbeers = spark.read.load(\"/FileStore/tables/beer_reviews.csv\", format='csv', header = True)\nbeers.createOrReplaceTempView(\"beer_reviews\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["## Display raw data\ndisplay(beers.take(5))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>brewery_id</th><th>brewery_name</th><th>review_time</th><th>review_overall</th><th>review_aroma</th><th>review_appearance</th><th>review_profilename</th><th>beer_style</th><th>review_palate</th><th>review_taste</th><th>beer_name</th><th>beer_abv</th><th>beer_beerid</th></tr></thead><tbody><tr><td>10325</td><td>Vecchio Birraio</td><td>1234817823</td><td>1.5</td><td>2</td><td>2.5</td><td>stcules</td><td>Hefeweizen</td><td>1.5</td><td>1.5</td><td>Sausa Weizen</td><td>5</td><td>47986</td></tr><tr><td>10325</td><td>Vecchio Birraio</td><td>1235915097</td><td>3</td><td>2.5</td><td>3</td><td>stcules</td><td>English Strong Ale</td><td>3</td><td>3</td><td>Red Moon</td><td>6.2</td><td>48213</td></tr><tr><td>10325</td><td>Vecchio Birraio</td><td>1235916604</td><td>3</td><td>2.5</td><td>3</td><td>stcules</td><td>Foreign / Export Stout</td><td>3</td><td>3</td><td>Black Horse Black Beer</td><td>6.5</td><td>48215</td></tr><tr><td>10325</td><td>Vecchio Birraio</td><td>1234725145</td><td>3</td><td>3</td><td>3.5</td><td>stcules</td><td>German Pilsener</td><td>2.5</td><td>3</td><td>Sausa Pils</td><td>5</td><td>47969</td></tr><tr><td>1075</td><td>Caldera Brewing Company</td><td>1293735206</td><td>4</td><td>4.5</td><td>4</td><td>johnmichaelsen</td><td>American Double / Imperial IPA</td><td>4</td><td>4.5</td><td>Cauldron DIPA</td><td>7.7</td><td>64883</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"code","source":["## The dimension of the dataframe\nprint((beers.count(), len(beers.columns)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(1586614, 13)\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["## Check Null\nprint(\"Is there missing value in the dataframe?\")\nprint('beers: {}'.format(beers.count() == beers.na.drop().count()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">beers: False\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["#### In this project, 1.5 millions of beer review data from BeerAdvocate through Kaggle will be analyzed.\n#### Reviewer information, beer Information and rating information are provided. \n##### Specifically, \n##### Beer information includes : Beer Name, Beer ABV, Beer ID, Beer Style, Brewery Name, Brewery ID.\n##### Rating infomration includes : Overall Ratings, Aroma Ratings, Apprearence Ratings, Palate Ratings, Taste Ratings.\n##### Reviewer information includes : Reviewer profilename, Review time."],"metadata":{}},{"cell_type":"code","source":["## Show data types\nbeers.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- brewery_id: string (nullable = true)\n-- brewery_name: string (nullable = true)\n-- review_time: string (nullable = true)\n-- review_overall: string (nullable = true)\n-- review_aroma: string (nullable = true)\n-- review_appearance: string (nullable = true)\n-- review_profilename: string (nullable = true)\n-- beer_style: string (nullable = true)\n-- review_palate: string (nullable = true)\n-- review_taste: string (nullable = true)\n-- beer_name: string (nullable = true)\n-- beer_abv: string (nullable = true)\n-- beer_beerid: string (nullable = true)\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["## Convert from spark dataframe to pandas dataframe\npandasbeer = beers.toPandas()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":13},{"cell_type":"code","source":["## Change reviewer profilename to userid\nlistOfStr = pandasbeer['review_profilename'].tolist()\nmy_dict = { i: listOfStr[i] for i in range(0, len(listOfStr) )}\nflipped_dict = dict(zip(my_dict.values(), my_dict.keys()))\npandasbeer['review_profilename'] = pandasbeer.review_profilename.map(flipped_dict)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["## Convert back to spark dataframe\nmybeer = spark.createDataFrame(pandasbeer)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"markdown","source":["### Exploratory data analysis\n#### In the first part of this project, I am going to explore what kind of data we get. \n##### I focused on beer style, since it might be an interesting characteristic that affects people's choice of beer. Other attributes, for example ABV, Style, Brewery should also be thoroughly explored if time allowed.\n##### In addition, since we also have Overall Ratings, Aroma Ratings, Apprearence Ratings, Palate Ratings, Taste Ratings information, it might be interesting to see the relationships between beer features and different categories of ratings. It would also be interesting to model the overall ratings using ratings from other categories."],"metadata":{}},{"cell_type":"code","source":["## Size of distinct items\nprint (\"number of distinct users\", mybeer.select('review_profilename').distinct().count())\nprint (\"number of distinct beers\", mybeer.select('beer_name').distinct().count())\nprint (\"number of distinct beer styles\", mybeer.select('beer_style').distinct().count())\nprint (\"number of distinct breweries\", mybeer.select('brewery_name').distinct().count())\nprint (\"number of distinct ABV\", mybeer.select('beer_abv').distinct().count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">number of distinct users 33388\nnumber of distinct beers 56857\nnumber of distinct beer styles 104\nnumber of distinct breweries 5743\nnumber of distinct ABV 531\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["#### Explore beer styles"],"metadata":{}},{"cell_type":"code","source":["## Unique Beer Styles\nunique_beer_style = mybeer.select('beer_style').distinct()\ndisplay(unique_beer_style)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["## The number of type of beers in each beer style\ndf_style= mybeer \\\n                    .groupBy('beer_style').count() \\\n                    .orderBy('count', ascending = False)\ndisplay(df_style)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>beer_style</th><th>count</th></tr></thead><tbody><tr><td>American IPA</td><td>117586</td></tr><tr><td>American Double / Imperial IPA</td><td>85977</td></tr><tr><td>American Pale Ale (APA)</td><td>63469</td></tr><tr><td>Russian Imperial Stout</td><td>54129</td></tr><tr><td>American Double / Imperial Stout</td><td>50705</td></tr><tr><td>American Porter</td><td>50477</td></tr><tr><td>American Amber / Red Ale</td><td>45751</td></tr><tr><td>Belgian Strong Dark Ale</td><td>37743</td></tr><tr><td>Fruit / Vegetable Beer</td><td>33861</td></tr><tr><td>American Strong Ale</td><td>31945</td></tr><tr><td>Belgian Strong Pale Ale</td><td>31490</td></tr><tr><td>Saison / Farmhouse Ale</td><td>31480</td></tr><tr><td>American Adjunct Lager</td><td>30749</td></tr><tr><td>Tripel</td><td>30328</td></tr><tr><td>Witbier</td><td>30140</td></tr><tr><td>Hefeweizen</td><td>27908</td></tr><tr><td>American Barleywine</td><td>26728</td></tr><tr><td>American Brown Ale</td><td>25297</td></tr><tr><td>American Stout</td><td>24538</td></tr><tr><td>American Pale Wheat Ale</td><td>24204</td></tr><tr><td>Märzen / Oktoberfest</td><td>23523</td></tr><tr><td>English Pale Ale</td><td>23402</td></tr><tr><td>German Pilsener</td><td>22155</td></tr><tr><td>Doppelbock</td><td>21699</td></tr><tr><td>Winter Warmer</td><td>20661</td></tr><tr><td>Dubbel</td><td>19983</td></tr><tr><td>English Brown Ale</td><td>19532</td></tr><tr><td>Belgian Pale Ale</td><td>19354</td></tr><tr><td>Oatmeal Stout</td><td>18145</td></tr><tr><td>Quadrupel (Quad)</td><td>18086</td></tr><tr><td>Euro Pale Lager</td><td>18015</td></tr><tr><td>American Wild Ale</td><td>17794</td></tr><tr><td>Scotch Ale / Wee Heavy</td><td>17441</td></tr><tr><td>Extra Special / Strong Bitter (ESB)</td><td>17212</td></tr><tr><td>English India Pale Ale (IPA)</td><td>15959</td></tr><tr><td>Pumpkin Ale</td><td>15550</td></tr><tr><td>Old Ale</td><td>14703</td></tr><tr><td>Light Lager</td><td>14311</td></tr><tr><td>English Barleywine</td><td>13731</td></tr><tr><td>Milk / Sweet Stout</td><td>13166</td></tr><tr><td>Czech Pilsener</td><td>12740</td></tr><tr><td>American Blonde Ale</td><td>12726</td></tr><tr><td>Irish Dry Stout</td><td>12595</td></tr><tr><td>Belgian IPA</td><td>12471</td></tr><tr><td>Baltic Porter</td><td>11572</td></tr><tr><td>Bock</td><td>11528</td></tr><tr><td>American Black Ale</td><td>11446</td></tr><tr><td>English Porter</td><td>11200</td></tr><tr><td>Lambic - Fruit</td><td>10950</td></tr><tr><td>Maibock / Helles Bock</td><td>10611</td></tr><tr><td>Herbed / Spiced Beer</td><td>10337</td></tr><tr><td>Rye Beer</td><td>10130</td></tr><tr><td>Schwarzbier</td><td>9826</td></tr><tr><td>Weizenbock</td><td>9412</td></tr><tr><td>American Amber / Red Lager</td><td>9311</td></tr><tr><td>Scottish Ale</td><td>9133</td></tr><tr><td>American Pale Lager</td><td>9099</td></tr><tr><td>Vienna Lager</td><td>8954</td></tr><tr><td>English Bitter</td><td>8787</td></tr><tr><td>Kölsch</td><td>8442</td></tr><tr><td>Munich Dunkel Lager</td><td>7941</td></tr><tr><td>Irish Red Ale</td><td>7877</td></tr><tr><td>Munich Helles Lager</td><td>7870</td></tr><tr><td>Altbier</td><td>7741</td></tr><tr><td>Dunkelweizen</td><td>7122</td></tr><tr><td>Bière de Garde</td><td>6729</td></tr><tr><td>Flanders Red Ale</td><td>6664</td></tr><tr><td>Belgian Dark Ale</td><td>6542</td></tr><tr><td>Gueuze</td><td>6009</td></tr><tr><td>Foreign / Export Stout</td><td>5972</td></tr><tr><td>American Double / Imperial Pilsner</td><td>5435</td></tr><tr><td>Cream Ale</td><td>5138</td></tr><tr><td>Flanders Oud Bruin</td><td>4995</td></tr><tr><td>English Strong Ale</td><td>4799</td></tr><tr><td>Euro Dark Lager</td><td>4657</td></tr><tr><td>Dortmunder / Export Lager</td><td>4440</td></tr><tr><td>California Common / Steam Beer</td><td>4038</td></tr><tr><td>Rauchbier</td><td>3962</td></tr><tr><td>American Malt Liquor</td><td>3925</td></tr><tr><td>Wheatwine</td><td>3714</td></tr><tr><td>Berliner Weissbier</td><td>3475</td></tr><tr><td>English Stout</td><td>3018</td></tr><tr><td>Smoked Beer</td><td>2986</td></tr><tr><td>Scottish Gruit / Ancient Herbed Ale</td><td>2751</td></tr><tr><td>Euro Strong Lager</td><td>2724</td></tr><tr><td>Eisbock</td><td>2663</td></tr><tr><td>Keller Bier / Zwickel Bier</td><td>2591</td></tr><tr><td>Black & Tan</td><td>2358</td></tr><tr><td>English Dark Mild Ale</td><td>2314</td></tr><tr><td>Chile Beer</td><td>2286</td></tr><tr><td>Kristalweizen</td><td>2204</td></tr><tr><td>Japanese Rice Lager</td><td>1546</td></tr><tr><td>American Dark Wheat Ale</td><td>1470</td></tr><tr><td>Low Alcohol Beer</td><td>1201</td></tr><tr><td>Lambic - Unblended</td><td>1114</td></tr><tr><td>Sahti</td><td>1061</td></tr><tr><td>Bière de Champagne / Bière Brut</td><td>1046</td></tr><tr><td>Braggot</td><td>1040</td></tr><tr><td>English Pale Mild Ale</td><td>700</td></tr><tr><td>Gose</td><td>686</td></tr><tr><td>Faro</td><td>609</td></tr><tr><td>Roggenbier</td><td>466</td></tr><tr><td>Kvass</td><td>297</td></tr><tr><td>Happoshu</td><td>241</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"code","source":["##Example of beers of belgian strong dark ale style\ndisplay(mybeer.where(\"beer_style like '%Belgian Strong Dark Ale%'\"))"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["#### Explore the overall ratings of beers"],"metadata":{}},{"cell_type":"code","source":["## The number of ratings of each scores\ndf_rate= mybeer \\\n                    .groupBy('review_overall').count() \\\n                    .orderBy('review_overall', ascending = False)\ndisplay(df_rate)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>review_overall</th><th>count</th></tr></thead><tbody><tr><td>5</td><td>91320</td></tr><tr><td>4.5</td><td>324385</td></tr><tr><td>4</td><td>582764</td></tr><tr><td>3.5</td><td>301817</td></tr><tr><td>3</td><td>165644</td></tr><tr><td>2.5</td><td>58523</td></tr><tr><td>2</td><td>38225</td></tr><tr><td>1.5</td><td>12975</td></tr><tr><td>1</td><td>10954</td></tr><tr><td>0</td><td>7</td></tr></tbody></table></div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["#### The average rating of beers from each beer style"],"metadata":{}},{"cell_type":"code","source":["pandasbeer['review_overall'] = pandasbeer['review_overall'].apply(pd.to_numeric)\npandasbeer.groupby(\"beer_style\")[\"review_overall\"].mean().sort_values(ascending = False).head(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[12]: beer_style\nAmerican Wild Ale                   4.093262\nGueuze                              4.086287\nQuadrupel (Quad)                    4.071630\nLambic - Unblended                  4.048923\nAmerican Double / Imperial Stout    4.029820\nRussian Imperial Stout              4.023084\nWeizenbock                          4.007969\nAmerican Double / Imperial IPA      3.998017\nFlanders Red Ale                    3.992722\nRye Beer                            3.981737\nName: review_overall, dtype: float64</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["#### The beers that have the most ratings"],"metadata":{}},{"cell_type":"code","source":["beerrated = pandasbeer.groupby('beer_name')['review_overall'].count().sort_values(ascending=False).head(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":27},{"cell_type":"markdown","source":["#### The number of ratings that each reviewer gave"],"metadata":{}},{"cell_type":"code","source":["pandasbeer.groupby('review_profilename')['review_overall'].count().sort_values(ascending=False).head(5) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: review_profilename\n1586535    5817\n1586244    4661\n1586246    4617\n1584562    3518\n1586447    3497\nName: review_overall, dtype: int64</div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["##### Although using this interesting dataset from BeerAdvocate, the project can go into many directions.\n##### In the rest part of this project, I am going to dive directly into predicting beer ratings only from review ID, and ratings that they gave to other beers."],"metadata":{}},{"cell_type":"markdown","source":["### Start to predict beer ratings using recommendation algorithms with Spark MLlib APIs"],"metadata":{}},{"cell_type":"code","source":["## Create a new dataframe only focusing on the beer, reviewer and the ratings that give.\ndf_rating_data = mybeer.select(\"review_profilename\",\"beer_beerid\",\"review_overall\")\ndf_rating_data = df_rating_data \\\n            .withColumn(\"review_profilename\", df_rating_data.review_profilename.cast(IntegerType())) \\\n            .withColumn(\"beer_beerid\", df_rating_data.beer_beerid.cast(IntegerType())) \\\n            .withColumn(\"review_overall\", df_rating_data.review_overall.cast(DoubleType())) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"code","source":["## Train and test split\ndata, hold_out = df_rating_data.randomSplit([0.8, 0.2], seed = 7856)\ndata.cache()\nhold_out.cache()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: DataFrame[review_profilename: int, beer_beerid: int, review_overall: double]</div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["#### Use ALS (Alternating Least Square) and collaborative filtering to predict the ratings for the movies\n#### ALS machine learning model referred from \n##### https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html"],"metadata":{}},{"cell_type":"code","source":["# Build the recommendation model using ALS on the training data\n\n# Specify model with parameters\nals = ml_als(userCol=\"review_profilename\", itemCol=\"beer_beerid\", ratingCol=\"review_overall\", coldStartStrategy=\"drop\")\n\n# Use a ParamGridBuilder to construct a grid of parameters to search over.\nparamGrid = ParamGridBuilder()\\\n    .addGrid(als.maxIter,[10]) \\\n    .addGrid(als.rank, [6, 8, 10, 12, 14])\\\n    .addGrid(als.regParam, [0.05, 0.1, 0,5, 1, 10])\\\n    .build()\n\n# Evaluate the model by computing the RMSE on the test data\nevaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"review_overall\",\n                                predictionCol=\"prediction\")\n\ntvs = CrossValidator(estimator=als,\n                     estimatorParamMaps=paramGrid,\n                     evaluator=evaluator,\n                     numFolds = 5)\n\n# fit data\nmyalsmodel = tvs.fit(data)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3410363378860028&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     21</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     22</span> <span class=\"ansi-red-fg\"># fit data</span>\n<span class=\"ansi-green-fg\">---&gt; 23</span><span class=\"ansi-red-fg\"> </span>myalsmodel <span class=\"ansi-blue-fg\">=</span> tvs<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>data<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, dataset, params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    130</span>                 <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>copy<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 132</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    133</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             raise ValueError(&#34;Params must be either a param map or a list/tuple of param maps, &#34;\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansi-cyan-fg\">_fit</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    308</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    309</span>             tasks <span class=\"ansi-blue-fg\">=</span> _parallelFitTasks<span class=\"ansi-blue-fg\">(</span>est<span class=\"ansi-blue-fg\">,</span> train<span class=\"ansi-blue-fg\">,</span> eva<span class=\"ansi-blue-fg\">,</span> validation<span class=\"ansi-blue-fg\">,</span> epm<span class=\"ansi-blue-fg\">,</span> collectSubModelsParam<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 310</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">for</span> j<span class=\"ansi-blue-fg\">,</span> metric<span class=\"ansi-blue-fg\">,</span> subModel <span class=\"ansi-green-fg\">in</span> pool<span class=\"ansi-blue-fg\">.</span>imap_unordered<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> f<span class=\"ansi-blue-fg\">:</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> tasks<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    311</span>                 metrics<span class=\"ansi-blue-fg\">[</span>j<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">+=</span> <span class=\"ansi-blue-fg\">(</span>metric <span class=\"ansi-blue-fg\">/</span> nFolds<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    312</span>                 metrics_all<span class=\"ansi-blue-fg\">[</span>i<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">[</span>j<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> metric\n\n<span class=\"ansi-green-fg\">/usr/lib/python3.7/multiprocessing/pool.py</span> in <span class=\"ansi-cyan-fg\">next</span><span class=\"ansi-blue-fg\">(self, timeout)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    746</span>         <span class=\"ansi-green-fg\">if</span> success<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    747</span>             <span class=\"ansi-green-fg\">return</span> value\n<span class=\"ansi-green-fg\">--&gt; 748</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">raise</span> value\n<span class=\"ansi-green-intense-fg ansi-bold\">    749</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    750</span>     __next__ <span class=\"ansi-blue-fg\">=</span> next                    <span class=\"ansi-red-fg\"># XXX</span>\n\n<span class=\"ansi-green-fg\">/usr/lib/python3.7/multiprocessing/pool.py</span> in <span class=\"ansi-cyan-fg\">worker</span><span class=\"ansi-blue-fg\">(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    119</span>         job<span class=\"ansi-blue-fg\">,</span> i<span class=\"ansi-blue-fg\">,</span> func<span class=\"ansi-blue-fg\">,</span> args<span class=\"ansi-blue-fg\">,</span> kwds <span class=\"ansi-blue-fg\">=</span> task\n<span class=\"ansi-green-intense-fg ansi-bold\">    120</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 121</span><span class=\"ansi-red-fg\">             </span>result <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">True</span><span class=\"ansi-blue-fg\">,</span> func<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>args<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kwds<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    122</span>         <span class=\"ansi-green-fg\">except</span> Exception <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    123</span>             <span class=\"ansi-green-fg\">if</span> wrap_exception <span class=\"ansi-green-fg\">and</span> func <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> _helper_reraises_exception<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansi-cyan-fg\">&lt;lambda&gt;</span><span class=\"ansi-blue-fg\">(f)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    308</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    309</span>             tasks <span class=\"ansi-blue-fg\">=</span> _parallelFitTasks<span class=\"ansi-blue-fg\">(</span>est<span class=\"ansi-blue-fg\">,</span> train<span class=\"ansi-blue-fg\">,</span> eva<span class=\"ansi-blue-fg\">,</span> validation<span class=\"ansi-blue-fg\">,</span> epm<span class=\"ansi-blue-fg\">,</span> collectSubModelsParam<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 310</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">for</span> j<span class=\"ansi-blue-fg\">,</span> metric<span class=\"ansi-blue-fg\">,</span> subModel <span class=\"ansi-green-fg\">in</span> pool<span class=\"ansi-blue-fg\">.</span>imap_unordered<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> f<span class=\"ansi-blue-fg\">:</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> tasks<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    311</span>                 metrics<span class=\"ansi-blue-fg\">[</span>j<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">+=</span> <span class=\"ansi-blue-fg\">(</span>metric <span class=\"ansi-blue-fg\">/</span> nFolds<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    312</span>                 metrics_all<span class=\"ansi-blue-fg\">[</span>i<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">[</span>j<span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">=</span> metric\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/tuning.py</span> in <span class=\"ansi-cyan-fg\">singleTask</span><span class=\"ansi-blue-fg\">()</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     52</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     53</span>     <span class=\"ansi-green-fg\">def</span> singleTask<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 54</span><span class=\"ansi-red-fg\">         </span>index<span class=\"ansi-blue-fg\">,</span> model <span class=\"ansi-blue-fg\">=</span> next<span class=\"ansi-blue-fg\">(</span>modelIter<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     55</span>         metric <span class=\"ansi-blue-fg\">=</span> eva<span class=\"ansi-blue-fg\">.</span>evaluate<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">.</span>transform<span class=\"ansi-blue-fg\">(</span>validation<span class=\"ansi-blue-fg\">,</span> epm<span class=\"ansi-blue-fg\">[</span>index<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     56</span>         <span class=\"ansi-green-fg\">return</span> index<span class=\"ansi-blue-fg\">,</span> metric<span class=\"ansi-blue-fg\">,</span> model <span class=\"ansi-green-fg\">if</span> collectSubModel <span class=\"ansi-green-fg\">else</span> <span class=\"ansi-green-fg\">None</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansi-cyan-fg\">__next__</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     60</span>                 <span class=\"ansi-green-fg\">raise</span> StopIteration<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;No models remaining.&#34;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>             self<span class=\"ansi-blue-fg\">.</span>counter <span class=\"ansi-blue-fg\">+=</span> <span class=\"ansi-cyan-fg\">1</span>\n<span class=\"ansi-green-fg\">---&gt; 62</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> index<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>fitSingleModel<span class=\"ansi-blue-fg\">(</span>index<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     63</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>     <span class=\"ansi-green-fg\">def</span> next<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansi-cyan-fg\">fitSingleModel</span><span class=\"ansi-blue-fg\">(index)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    104</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    105</span>         <span class=\"ansi-green-fg\">def</span> fitSingleModel<span class=\"ansi-blue-fg\">(</span>index<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 106</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> estimator<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">,</span> paramMaps<span class=\"ansi-blue-fg\">[</span>index<span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    107</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    108</span>         <span class=\"ansi-green-fg\">return</span> _FitMultipleIterator<span class=\"ansi-blue-fg\">(</span>fitSingleModel<span class=\"ansi-blue-fg\">,</span> len<span class=\"ansi-blue-fg\">(</span>paramMaps<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/base.py</span> in <span class=\"ansi-cyan-fg\">fit</span><span class=\"ansi-blue-fg\">(self, dataset, params)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">elif</span> isinstance<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">,</span> dict<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             <span class=\"ansi-green-fg\">if</span> params<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 130</span><span class=\"ansi-red-fg\">                 </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>copy<span class=\"ansi-blue-fg\">(</span>params<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_fit</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    293</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    294</span>     <span class=\"ansi-green-fg\">def</span> _fit<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dataset<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 295</span><span class=\"ansi-red-fg\">         </span>java_model <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_fit_java<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    296</span>         model <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_create_model<span class=\"ansi-blue-fg\">(</span>java_model<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    297</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_copyValues<span class=\"ansi-blue-fg\">(</span>model<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/ml/wrapper.py</span> in <span class=\"ansi-cyan-fg\">_fit_java</span><span class=\"ansi-blue-fg\">(self, dataset)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    290</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">    291</span>         self<span class=\"ansi-blue-fg\">.</span>_transfer_params_to_java<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 292</span><span class=\"ansi-red-fg\">         </span><span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_java_obj<span class=\"ansi-blue-fg\">.</span>fit<span class=\"ansi-blue-fg\">(</span>dataset<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    293</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    294</span>     <span class=\"ansi-green-fg\">def</span> _fit<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">,</span> dataset<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1255</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1256</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1257</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1258</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1259</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     61</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     62</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 63</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     64</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     65</span>             s <span class=\"ansi-blue-fg\">=</span> e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">.</span>toString<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o4305.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 707.0 failed 1 times, most recent failure: Lost task 4.0 in stage 707.0 (TID 6609, localhost, executor driver): org.apache.spark.ml.optim.SingularMatrixException: LAPACK.dppsv returned 2 because A is not positive definite. Is A derived from a singular matrix (e.g. collinear column values)?\n\tat org.apache.spark.mllib.linalg.CholeskyDecomposition$.checkReturnValue(CholeskyDecomposition.scala:65)\n\tat org.apache.spark.mllib.linalg.CholeskyDecomposition$.solve(CholeskyDecomposition.scala:41)\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:749)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1701)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1662)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$37$$anonfun$apply$38.apply(PairRDDFunctions.scala:757)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$37$$anonfun$apply$38.apply(PairRDDFunctions.scala:757)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:157)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:166)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:165)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:165)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:140)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:113)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:537)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:543)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2362)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2350)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2349)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2349)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1102)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1102)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1102)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2582)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2529)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2517)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:897)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2280)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2302)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2321)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2346)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1220)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:1032)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$fit$1.apply(ALS.scala:677)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$fit$1.apply(ALS.scala:659)\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$14.apply(Instrumentation.scala:277)\n\tat scala.util.Try$.apply(Try.scala:192)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:277)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:659)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.ml.optim.SingularMatrixException: LAPACK.dppsv returned 2 because A is not positive definite. Is A derived from a singular matrix (e.g. collinear column values)?\n\tat org.apache.spark.mllib.linalg.CholeskyDecomposition$.checkReturnValue(CholeskyDecomposition.scala:65)\n\tat org.apache.spark.mllib.linalg.CholeskyDecomposition$.solve(CholeskyDecomposition.scala:41)\n\tat org.apache.spark.ml.recommendation.ALS$CholeskySolver.solve(ALS.scala:749)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1701)\n\tat org.apache.spark.ml.recommendation.ALS$$anonfun$org$apache$spark$ml$recommendation$ALS$$computeFactors$1.apply(ALS.scala:1662)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$37$$anonfun$apply$38.apply(PairRDDFunctions.scala:757)\n\tat org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$37$$anonfun$apply$38.apply(PairRDDFunctions.scala:757)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:157)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:166)\n\tat org.apache.spark.rdd.CoGroupedRDD$$anonfun$compute$4.apply(CoGroupedRDD.scala:165)\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\n\tat org.apache.spark.rdd.CoGroupedRDD.compute(CoGroupedRDD.scala:165)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:353)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:317)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:140)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:113)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:537)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1541)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:543)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n</div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["#### Evaluate the model by computing the RMSE on the test data"],"metadata":{}},{"cell_type":"code","source":["# Get the best model from cross validation, evaluate the best model on test data\nbest_model = myalsmodel.bestModel\npredictions = best_model.transform(hold_out)\nrmse = evaluator.evaluate(predictions)\nprint(\"Root-mean-square error = \" + str(rmse))"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["#Print evaluation metrics and model parameters\nprint (\"RMSE = \"+str(rmse))\nprint (\"**Best Model**\")\nprint (\" Rank:\"+str(best_model._java_obj.parent().getRank())), \nprint (\" MaxIter:\"+str(best_model._java_obj.parent().getMaxIter())), \nprint (\" RegParam:\"+str(best_model._java_obj.parent().getRegParam()))"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["#### Show predicted ratings"],"metadata":{}},{"cell_type":"code","source":["## Show predictions\npredictions.show()"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["#### Generate the top 5 beer recommendations for each user\n#### Generate the top 5 user recommendations for each beer"],"metadata":{}},{"cell_type":"code","source":["# Generate top 5 beer recommendations for user whose id is 666\nuserRecs = myalsmodel.bestModel.recommendForAllUsers(5).cache()\ndisplay(userRecs.filter(userRecs.userId == 666))"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["# Generate top 5 user recommendations for each beer\nbeerRecs = myalsmodel.bestModel.recommendForAllItems(5).cache()\ndisplay(beerRecs)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["### Discussion\n#### Matrix factorization with ALS algorithm was used in the rating prediction task.\n#### I used five-fold cross validation to train the model, selected the best model and evaluated on the testing data. \n#### Parameters including max iteration, regularization parameter, and rank were selected using grid search method. \n#### The best model showing the rank number gives us an insight of the number of the latent features in the ALS algorithm. The feature might be related to beer style, abv, brewery, aroma, appearance, palate, tasting and etc. A thorough exploration could be done latter. The findings might help in reinforcing the model using other method to improve the model in the future.\n#### The predicted beer ratings and recommendations for customers are also shown above, providing recommended beers to the specific customers.\n#### More explorations could be done using this dataset in possible future projects.\n##### I focused on beer style, since it might be an interesting characteristic that affects people's choice of beer. Other attributes, for example ABV, Style, Brewery should also be thoroughly explored if time allowed.\n##### In addition, since we also have Overall Ratings, Aroma Ratings, Apprearence Ratings, Palate Ratings, Taste Ratings information, it might be interesting to see the relationships between beer features and different categories of ratings. It would also be interesting to model the overall ratings using ratings from other categories, at least plot the distribution of theses ratings or run a simple linear regression."],"metadata":{}},{"cell_type":"markdown","source":["### Appendix for all the columns in the dataset \n##### Reviewer Information : Reviewer profilename, Review time\n###### review_profilename \n###### review_time\n##### Rating Information : Overall Ratings, Aroma Ratings, Apprearence Ratings, Palate Ratings, Taste Ratings\n###### review_overall\n###### review_aroma\n###### review_appearance\n###### review_palate\n###### review_taste\n##### Beer Information: Beer Name, Beer ABV, Beer ID, Beer Style, Brewery Name, Brewery ID\n###### beer_name\n###### beer_abv\n###### beer_beerid\n###### beer_style\n###### brewery_name\n###### brewery_id"],"metadata":{}},{"cell_type":"markdown","source":["### References \n##### https://www.kaggle.com/rdoume/beerreviews\n##### https://hub.packtpub.com/building-recommendation-engine-spark/ \n##### https://www.analyticsvidhya.com/blog/2016/06/quick-guide-build-recommendation-engine-python/ \n##### https://blog.statsbot.co/recommendation-system-algorithms-ba67f39ac9a3"],"metadata":{}}],"metadata":{"name":"Beer Review","notebookId":3410363378859995},"nbformat":4,"nbformat_minor":0}
